{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\mural\\anaconda3\\lib\\site-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Using cached pip-25.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mural\\anaconda3\\lib\\site-packages (68.2.2)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-75.8.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: wheel in c:\\users\\mural\\anaconda3\\lib\\site-packages (0.41.2)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached pip-25.0-py3-none-any.whl (1.8 MB)\n",
      "Using cached setuptools-75.8.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, setuptools, pip\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.41.2\n",
      "    Uninstalling wheel-0.41.2:\n",
      "      Successfully uninstalled wheel-0.41.2\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 68.2.2\n",
      "    Uninstalling setuptools-68.2.2:\n",
      "      Successfully uninstalled setuptools-68.2.2\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.1\n",
      "    Uninstalling pip-23.3.1:\n",
      "      Successfully uninstalled pip-23.3.1\n",
      "Successfully installed pip-25.0 setuptools-75.8.0 wheel-0.45.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U pip setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.3-cp39-cp39-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.12-cp39-cp39-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp39-cp39-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading preshed-3.0.9-cp39-cp39-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy)\n",
      "  Downloading thinc-8.3.4-cp39-cp39-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp39-cp39-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mural\\anaconda3\\lib\\site-packages (from spacy) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.0->spacy)\n",
      "  Downloading blis-1.2.0-cp39-cp39-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.0->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\mural\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.2)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp39-cp39-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mural\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Downloading spacy-3.8.3-cp39-cp39-win_amd64.whl (12.3 MB)\n",
      "   ---------------------------------------- 0.0/12.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.1/12.3 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.2/12.3 MB 12.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.3/12.3 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.3/12.3 MB 13.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.3/12.3 MB 12.8 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp39-cp39-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.12-cp39-cp39-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp39-cp39-win_amd64.whl (122 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp39-cp39-win_amd64.whl (633 kB)\n",
      "   ---------------------------------------- 0.0/633.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 633.4/633.4 kB 12.0 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.4-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 19.7 MB/s eta 0:00:00\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.2.0-cp39-cp39-win_amd64.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 3.9/6.2 MB 19.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 15.3 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.1/5.4 MB 13.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 14.9 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading marisa_trie-1.2.1-cp39-cp39-win_amd64.whl (152 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, shellingham, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 preshed-3.0.9 shellingham-1.5.4 spacy-3.8.3 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 typer-0.15.1 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    }
   ],
   "source": [
    "pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 13.3 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 5.0/12.8 MB 15.1 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 14.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.7/12.8 MB 14.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 14.1 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting el-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/el_core_news_sm-3.8.0/el_core_news_sm-3.8.0-py3-none-any.whl (12.6 MB)\n",
      "     ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 2.1/12.6 MB 13.1 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 4.7/12.6 MB 13.0 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.9/12.6 MB 13.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 11.5/12.6 MB 14.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.6/12.6 MB 13.4 MB/s eta 0:00:00\n",
      "Installing collected packages: el-core-news-sm\n",
      "Successfully installed el-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('el_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download el_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_en = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_grk = spacy.load(\"el_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"greek_text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Τρώω φρούτα κάθε μέρα. (Tróo froúta káthe méra.) - I eat fruit every day.\n",
      "Τρώω ψωμί με βούτυρο. (Tróo psomí me voútyro.) - I eat bread with butter.\n",
      "Τρώω ένα μήλο το πρωί. (Tróo éna mílo to proí.) - I eat an apple in the morning.\n",
      "Τρώω σαλάτα με ντομάτα. (Tróo saláta me ntomáta.) - I eat salad with tomato.\n",
      "Τρώω ζυμαρικά για μεσημεριανό. (Tróo zymariká gia mesimerianó.) - I eat pasta for lunch.\n",
      "Τρώω κοτόπουλο για δείπνο. (Tróo kotópoulo gia deípno.) - I eat chicken for dinner.\n",
      "Τρώω αυγά το Σαββατοκύριακο. (Tróo avgá to Savvatokyriako.) - I eat eggs on the weekend.\n",
      "Τρώω ρύζι με λαχανικά. (Tróo rýzi me lachaniká.) - I eat rice with vegetables.\n",
      "Τρώω γιαούρτι με μέλι. (Tróo giaoúrti me méli.) - I eat yogurt with honey.\n",
      "Τρώω τυρί και ελιές. (Tróo tyrí kai eliés.) - I eat cheese and olives.\n",
      "Αγαπώ τα φρούτα, ειδικά τα μήλα. (Agapó ta froúta, eidiká ta míla.) - I love fruits, especially apples.\n",
      "Έχεις ψωμί; (Écheis psomí?) - Do you have bread?\n",
      "Κάθε πρωί τρώω ένα μήλο. (Káthe proí tróo éna mílo.) - Every morning I eat an apple.\n",
      "Θέλω να φάω σαλάτα με ντομάτες. (Thélo na fáo saláta me ntomátes.) - I want to eat salad with tomatoes.\n",
      "Η σούπα έχει κοτόπουλο και λαχανικά. (I soúpa échei kotópoulo kai lachaniká.) - The soup has chicken and vegetables.\n",
      "Πόσο κοστίζει το ψωμί; (Póso kostízei to psomí?) - How much does the bread cost?\n",
      "Πίνω γάλα με το μήλο μου. (Píno gála me to mílo mou.) - I drink milk with my apple.\n",
      "Μετά το δείπνο, τρώμε συχνά φρούτα. (Metá to deípno, tróme synchá froúta.) - After dinner, we often eat fruits.\n",
      "Στη σαλάτα, βάζω πάντα ντομάτες. (Sti saláta, vázo pánta ntomátes.) - In the salad, I always put tomatoes.\n",
      "Ποιος έφαγε το ψωμί; (Pios éfage to psomí?) - Who ate the bread?\n",
      "Το κοτόπουλο είναι το αγαπημένο μου φαγητό. (To kotópoulo eínai to agapiméno mou fagitó.) - Chicken is my favorite food.\n",
      "Μπορώ να έχω λίγο περισσότερο ψωμί, παρακαλώ; (Boró na écho lígo perissótero psomí, parakaló?) - Can I have a little more bread, please?\n",
      "Αυτή η μηλόπιτα είναι πολύ νόστιμη. (Aftí i milópita eínai polý nóstimi.) - This apple pie is very delicious.\n",
      "Πού αγόρασες αυτά τα φρέσκα φρούτα; (Poú agórases aftá ta fréska froúta?) - Where did you buy these fresh fruits?\n",
      "Φτιάχνω σαλάτα με ντομάτες και αγγούρια. (Ftiáchno saláta me ntomátes kai angouría.) - I am making a salad with tomatoes and cucumbers.\n",
      "Θα πιείτε γάλα ή χυμό; (Tha pieíte gála í chymó?) - Will you drink milk or juice?\n",
      "Τα παιδιά δεν τρώνε πολύ ψωμί. (Ta paidiá den tróne polý psomí.) - The children don’t eat much bread.\n",
      "Αυτές οι ντομάτες είναι πολύ ώριμες. (Aftés oi ntomátes eínai polý órimes.) - These tomatoes are very ripe.\n",
      "Στο πρωινό μου πάντα έχω ένα μήλο. (Sto proinó mou pánta écho éna mílo.) - For my breakfast, I always have an apple.\n",
      "Τα φρούτα είναι καλά για την υγεία. (Ta froúta eínai kalá gia tin ygeía.) - Fruits are good for health.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Τρώω φρούτα κάθε μέρα.  - I eat fruit every day.\n",
      "Τρώω ψωμί με βούτυρο.  - I eat bread with butter.\n",
      "Τρώω ένα μήλο το πρωί.  - I eat an apple in the morning.\n",
      "Τρώω σαλάτα με ντομάτα.  - I eat salad with tomato.\n",
      "Τρώω ζυμαρικά για μεσημεριανό.  - I eat pasta for lunch.\n",
      "Τρώω κοτόπουλο για δείπνο.  - I eat chicken for dinner.\n",
      "Τρώω αυγά το Σαββατοκύριακο.  - I eat eggs on the weekend.\n",
      "Τρώω ρύζι με λαχανικά.  - I eat rice with vegetables.\n",
      "Τρώω γιαούρτι με μέλι.  - I eat yogurt with honey.\n",
      "Τρώω τυρί και ελιές.  - I eat cheese and olives.\n",
      "Αγαπώ τα φρούτα, ειδικά τα μήλα.  - I love fruits, especially apples.\n",
      "Έχεις ψωμί;  - Do you have bread?\n",
      "Κάθε πρωί τρώω ένα μήλο.  - Every morning I eat an apple.\n",
      "Θέλω να φάω σαλάτα με ντομάτες.  - I want to eat salad with tomatoes.\n",
      "Η σούπα έχει κοτόπουλο και λαχανικά.  - The soup has chicken and vegetables.\n",
      "Πόσο κοστίζει το ψωμί;  - How much does the bread cost?\n",
      "Πίνω γάλα με το μήλο μου.  - I drink milk with my apple.\n",
      "Μετά το δείπνο, τρώμε συχνά φρούτα.  - After dinner, we often eat fruits.\n",
      "Στη σαλάτα, βάζω πάντα ντομάτες.  - In the salad, I always put tomatoes.\n",
      "Ποιος έφαγε το ψωμί;  - Who ate the bread?\n",
      "Το κοτόπουλο είναι το αγαπημένο μου φαγητό.  - Chicken is my favorite food.\n",
      "Μπορώ να έχω λίγο περισσότερο ψωμί, παρακαλώ;  - Can I have a little more bread, please?\n",
      "Αυτή η μηλόπιτα είναι πολύ νόστιμη.  - This apple pie is very delicious.\n",
      "Πού αγόρασες αυτά τα φρέσκα φρούτα;  - Where did you buy these fresh fruits?\n",
      "Φτιάχνω σαλάτα με ντομάτες και αγγούρια.  - I am making a salad with tomatoes and cucumbers.\n",
      "Θα πιείτε γάλα ή χυμό;  - Will you drink milk or juice?\n",
      "Τα παιδιά δεν τρώνε πολύ ψωμί.  - The children don’t eat much bread.\n",
      "Αυτές οι ντομάτες είναι πολύ ώριμες.  - These tomatoes are very ripe.\n",
      "Στο πρωινό μου πάντα έχω ένα μήλο.  - For my breakfast, I always have an apple.\n",
      "Τα φρούτα είναι καλά για την υγεία.  - Fruits are good for health.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "clean_text = re.sub(\"\\(.*\\)\", \"\", text)\n",
    "\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Τρώω φρούτα κάθε μέρα.  \n",
      "Τρώω ψωμί με βούτυρο.  \n",
      "Τρώω ένα μήλο το πρωί.  \n",
      "Τρώω σαλάτα με ντομάτα.  \n",
      "Τρώω ζυμαρικά για μεσημεριανό.  \n",
      "Τρώω κοτόπουλο για δείπνο.  \n",
      "Τρώω αυγά το Σαββατοκύριακο.  \n",
      "Τρώω ρύζι με λαχανικά.  \n",
      "Τρώω γιαούρτι με μέλι.  \n",
      "Τρώω τυρί και ελιές.  \n",
      "Αγαπώ τα φρούτα, ειδικά τα μήλα.  \n",
      "Έχεις ψωμί;  \n",
      "Κάθε πρωί τρώω ένα μήλο.  \n",
      "Θέλω να φάω σαλάτα με ντομάτες.  \n",
      "Η σούπα έχει κοτόπουλο και λαχανικά.  \n",
      "Πόσο κοστίζει το ψωμί;  \n",
      "Πίνω γάλα με το μήλο μου.  \n",
      "Μετά το δείπνο, τρώμε συχνά φρούτα.  \n",
      "Στη σαλάτα, βάζω πάντα ντομάτες.  \n",
      "Ποιος έφαγε το ψωμί;  \n",
      "Το κοτόπουλο είναι το αγαπημένο μου φαγητό.  \n",
      "Μπορώ να έχω λίγο περισσότερο ψωμί, παρακαλώ;  \n",
      "Αυτή η μηλόπιτα είναι πολύ νόστιμη.  \n",
      "Πού αγόρασες αυτά τα φρέσκα φρούτα;  \n",
      "Φτιάχνω σαλάτα με ντομάτες και αγγούρια.  \n",
      "Θα πιείτε γάλα ή χυμό;  \n",
      "Τα παιδιά δεν τρώνε πολύ ψωμί.  \n",
      "Αυτές οι ντομάτες είναι πολύ ώριμες.  \n",
      "Στο πρωινό μου πάντα έχω ένα μήλο.  \n",
      "Τα φρούτα είναι καλά για την υγεία.  \n"
     ]
    }
   ],
   "source": [
    "clean_text2 = re.sub(\"-.*[\\.\\?]\", \"\", clean_text)\n",
    "\n",
    "print(clean_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Τρώω φρούτα κάθε μέρα. Τρώω ψωμί με βούτυρο. Τρώω ένα μήλο το πρωί. Τρώω σαλάτα με ντομάτα. Τρώω ζυμαρικά για μεσημεριανό. Τρώω κοτόπουλο για δείπνο. Τρώω αυγά το Σαββατοκύριακο. Τρώω ρύζι με λαχανικά. Τρώω γιαούρτι με μέλι. Τρώω τυρί και ελιές. Αγαπώ τα φρούτα, ειδικά τα μήλα. Έχεις ψωμί; Κάθε πρωί τρώω ένα μήλο. Θέλω να φάω σαλάτα με ντομάτες. Η σούπα έχει κοτόπουλο και λαχανικά. Πόσο κοστίζει το ψωμί; Πίνω γάλα με το μήλο μου. Μετά το δείπνο, τρώμε συχνά φρούτα. Στη σαλάτα, βάζω πάντα ντομάτες. Ποιος έφαγε το ψωμί; Το κοτόπουλο είναι το αγαπημένο μου φαγητό. Μπορώ να έχω λίγο περισσότερο ψωμί, παρακαλώ; Αυτή η μηλόπιτα είναι πολύ νόστιμη. Πού αγόρασες αυτά τα φρέσκα φρούτα; Φτιάχνω σαλάτα με ντομάτες και αγγούρια. Θα πιείτε γάλα ή χυμό; Τα παιδιά δεν τρώνε πολύ ψωμί. Αυτές οι ντομάτες είναι πολύ ώριμες. Στο πρωινό μου πάντα έχω ένα μήλο. Τα φρούτα είναι καλά για την υγεία.\n"
     ]
    }
   ],
   "source": [
    "lines = clean_text2.split(\"\\n\")\n",
    "\n",
    "cleaned_lines = []\n",
    "for line in lines:\n",
    "    cleaned_line = line.rstrip()\n",
    "    cleaned_lines.append(cleaned_line)\n",
    "\n",
    "final_text = \" \".join(cleaned_lines)\n",
    "\n",
    "print(final_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Τρώω\n",
      "φρούτα\n",
      "κάθε\n",
      "μέρα\n",
      ".\n",
      "Τρώω\n",
      "ψωμί\n",
      "με\n",
      "βούτυρο\n",
      ".\n",
      "Τρώω\n",
      "ένα\n",
      "μήλο\n",
      "το\n",
      "πρωί\n",
      ".\n",
      "Τρώω\n",
      "σαλάτα\n",
      "με\n",
      "ντομάτα\n",
      ".\n",
      "Τρώω\n",
      "ζυμαρικά\n",
      "για\n",
      "μεσημεριανό\n",
      ".\n",
      "Τρώω\n",
      "κοτόπουλο\n",
      "για\n",
      "δείπνο\n",
      ".\n",
      "Τρώω\n",
      "αυγά\n",
      "το\n",
      "Σαββατοκύριακο\n",
      ".\n",
      "Τρώω\n",
      "ρύζι\n",
      "με\n",
      "λαχανικά\n",
      ".\n",
      "Τρώω\n",
      "γιαούρτι\n",
      "με\n",
      "μέλι\n",
      ".\n",
      "Τρώω\n",
      "τυρί\n",
      "και\n",
      "ελιές\n",
      ".\n",
      "Αγαπώ\n",
      "τα\n",
      "φρούτα\n",
      ",\n",
      "ειδικά\n",
      "τα\n",
      "μήλα\n",
      ".\n",
      "Έχεις\n",
      "ψωμί\n",
      ";\n",
      "Κάθε\n",
      "πρωί\n",
      "τρώω\n",
      "ένα\n",
      "μήλο\n",
      ".\n",
      "Θέλω\n",
      "να\n",
      "φάω\n",
      "σαλάτα\n",
      "με\n",
      "ντομάτες\n",
      ".\n",
      "Η\n",
      "σούπα\n",
      "έχει\n",
      "κοτόπουλο\n",
      "και\n",
      "λαχανικά\n",
      ".\n",
      "Πόσο\n",
      "κοστίζει\n",
      "το\n",
      "ψωμί\n",
      ";\n",
      "Πίνω\n",
      "γάλα\n",
      "με\n",
      "το\n",
      "μήλο\n",
      "μου\n",
      ".\n",
      "Μετά\n",
      "το\n",
      "δείπνο\n",
      ",\n",
      "τρώμε\n",
      "συχνά\n",
      "φρούτα\n",
      ".\n",
      "Στη\n",
      "σαλάτα\n",
      ",\n",
      "βάζω\n",
      "πάντα\n",
      "ντομάτες\n",
      ".\n",
      "Ποιος\n",
      "έφαγε\n",
      "το\n",
      "ψωμί\n",
      ";\n",
      "Το\n",
      "κοτόπουλο\n",
      "είναι\n",
      "το\n",
      "αγαπημένο\n",
      "μου\n",
      "φαγητό\n",
      ".\n",
      "Μπορώ\n",
      "να\n",
      "έχω\n",
      "λίγο\n",
      "περισσότερο\n",
      "ψωμί\n",
      ",\n",
      "παρακαλώ\n",
      ";\n",
      "Αυτή\n",
      "η\n",
      "μηλόπιτα\n",
      "είναι\n",
      "πολύ\n",
      "νόστιμη\n",
      ".\n",
      "Πού\n",
      "αγόρασες\n",
      "αυτά\n",
      "τα\n",
      "φρέσκα\n",
      "φρούτα\n",
      ";\n",
      "Φτιάχνω\n",
      "σαλάτα\n",
      "με\n",
      "ντομάτες\n",
      "και\n",
      "αγγούρια\n",
      ".\n",
      "Θα\n",
      "πιείτε\n",
      "γάλα\n",
      "ή\n",
      "χυμό\n",
      ";\n",
      "Τα\n",
      "παιδιά\n",
      "δεν\n",
      "τρώνε\n",
      "πολύ\n",
      "ψωμί\n",
      ".\n",
      "Αυτές\n",
      "οι\n",
      "ντομάτες\n",
      "είναι\n",
      "πολύ\n",
      "ώριμες\n",
      ".\n",
      "Στο\n",
      "πρωινό\n",
      "μου\n",
      "πάντα\n",
      "έχω\n",
      "ένα\n",
      "μήλο\n",
      ".\n",
      "Τα\n",
      "φρούτα\n",
      "είναι\n",
      "καλά\n",
      "για\n",
      "την\n",
      "υγεία\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "#Tokenizing the corpus\n",
    "doc = nlp_grk(final_text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Τρώω': 10, 'φρούτα': 5, 'κάθε': 1, 'μέρα': 1, '.': 24, 'ψωμί': 6, 'με': 7, 'βούτυρο': 1, 'ένα': 3, 'μήλο': 4, 'το': 7, 'πρωί': 2, 'σαλάτα': 4, 'ντομάτα': 1, 'ζυμαρικά': 1, 'για': 3, 'μεσημεριανό': 1, 'κοτόπουλο': 3, 'δείπνο': 2, 'αυγά': 1, 'Σαββατοκύριακο': 1, 'ρύζι': 1, 'λαχανικά': 2, 'γιαούρτι': 1, 'μέλι': 1, 'τυρί': 1, 'και': 3, 'ελιές': 1, 'Αγαπώ': 1, 'τα': 3, ',': 4, 'ειδικά': 1, 'μήλα': 1, 'Έχεις': 1, ';': 6, 'Κάθε': 1, 'τρώω': 1, 'Θέλω': 1, 'να': 2, 'φάω': 1, 'ντομάτες': 4, 'Η': 1, 'σούπα': 1, 'έχει': 1, 'Πόσο': 1, 'κοστίζει': 1, 'Πίνω': 1, 'γάλα': 2, 'μου': 3, 'Μετά': 1, 'τρώμε': 1, 'συχνά': 1, 'Στη': 1, 'βάζω': 1, 'πάντα': 2, 'Ποιος': 1, 'έφαγε': 1, 'Το': 1, 'είναι': 4, 'αγαπημένο': 1, 'φαγητό': 1, 'Μπορώ': 1, 'έχω': 2, 'λίγο': 1, 'περισσότερο': 1, 'παρακαλώ': 1, 'Αυτή': 1, 'η': 1, 'μηλόπιτα': 1, 'πολύ': 3, 'νόστιμη': 1, 'Πού': 1, 'αγόρασες': 1, 'αυτά': 1, 'φρέσκα': 1, 'Φτιάχνω': 1, 'αγγούρια': 1, 'Θα': 1, 'πιείτε': 1, 'ή': 1, 'χυμό': 1, 'Τα': 2, 'παιδιά': 1, 'δεν': 1, 'τρώνε': 1, 'Αυτές': 1, 'οι': 1, 'ώριμες': 1, 'Στο': 1, 'πρωινό': 1, 'καλά': 1, 'την': 1, 'υγεία': 1}\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "#counting unigrams\n",
    "unigram_count = {}\n",
    "for token in doc:\n",
    "    if token.text in unigram_count:\n",
    "        unigram_count[token.text] += 1\n",
    "    else:\n",
    "        unigram_count[token.text] = 1\n",
    "print(unigram_count)\n",
    "print(len(unigram_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Τρώω', 'φρούτα'): 1, ('φρούτα', 'κάθε'): 1, ('κάθε', 'μέρα'): 1, ('μέρα', '.'): 1, ('.', 'Τρώω'): 9, ('Τρώω', 'ψωμί'): 1, ('ψωμί', 'με'): 1, ('με', 'βούτυρο'): 1, ('βούτυρο', '.'): 1, ('Τρώω', 'ένα'): 1, ('ένα', 'μήλο'): 3, ('μήλο', 'το'): 1, ('το', 'πρωί'): 1, ('πρωί', '.'): 1, ('Τρώω', 'σαλάτα'): 1, ('σαλάτα', 'με'): 3, ('με', 'ντομάτα'): 1, ('ντομάτα', '.'): 1, ('Τρώω', 'ζυμαρικά'): 1, ('ζυμαρικά', 'για'): 1, ('για', 'μεσημεριανό'): 1, ('μεσημεριανό', '.'): 1, ('Τρώω', 'κοτόπουλο'): 1, ('κοτόπουλο', 'για'): 1, ('για', 'δείπνο'): 1, ('δείπνο', '.'): 1, ('Τρώω', 'αυγά'): 1, ('αυγά', 'το'): 1, ('το', 'Σαββατοκύριακο'): 1, ('Σαββατοκύριακο', '.'): 1, ('Τρώω', 'ρύζι'): 1, ('ρύζι', 'με'): 1, ('με', 'λαχανικά'): 1, ('λαχανικά', '.'): 2, ('Τρώω', 'γιαούρτι'): 1, ('γιαούρτι', 'με'): 1, ('με', 'μέλι'): 1, ('μέλι', '.'): 1, ('Τρώω', 'τυρί'): 1, ('τυρί', 'και'): 1, ('και', 'ελιές'): 1, ('ελιές', '.'): 1, ('.', 'Αγαπώ'): 1, ('Αγαπώ', 'τα'): 1, ('τα', 'φρούτα'): 1, ('φρούτα', ','): 1, (',', 'ειδικά'): 1, ('ειδικά', 'τα'): 1, ('τα', 'μήλα'): 1, ('μήλα', '.'): 1, ('.', 'Έχεις'): 1, ('Έχεις', 'ψωμί'): 1, ('ψωμί', ';'): 3, (';', 'Κάθε'): 1, ('Κάθε', 'πρωί'): 1, ('πρωί', 'τρώω'): 1, ('τρώω', 'ένα'): 1, ('μήλο', '.'): 2, ('.', 'Θέλω'): 1, ('Θέλω', 'να'): 1, ('να', 'φάω'): 1, ('φάω', 'σαλάτα'): 1, ('με', 'ντομάτες'): 2, ('ντομάτες', '.'): 2, ('.', 'Η'): 1, ('Η', 'σούπα'): 1, ('σούπα', 'έχει'): 1, ('έχει', 'κοτόπουλο'): 1, ('κοτόπουλο', 'και'): 1, ('και', 'λαχανικά'): 1, ('.', 'Πόσο'): 1, ('Πόσο', 'κοστίζει'): 1, ('κοστίζει', 'το'): 1, ('το', 'ψωμί'): 2, (';', 'Πίνω'): 1, ('Πίνω', 'γάλα'): 1, ('γάλα', 'με'): 1, ('με', 'το'): 1, ('το', 'μήλο'): 1, ('μήλο', 'μου'): 1, ('μου', '.'): 1, ('.', 'Μετά'): 1, ('Μετά', 'το'): 1, ('το', 'δείπνο'): 1, ('δείπνο', ','): 1, (',', 'τρώμε'): 1, ('τρώμε', 'συχνά'): 1, ('συχνά', 'φρούτα'): 1, ('φρούτα', '.'): 1, ('.', 'Στη'): 1, ('Στη', 'σαλάτα'): 1, ('σαλάτα', ','): 1, (',', 'βάζω'): 1, ('βάζω', 'πάντα'): 1, ('πάντα', 'ντομάτες'): 1, ('.', 'Ποιος'): 1, ('Ποιος', 'έφαγε'): 1, ('έφαγε', 'το'): 1, (';', 'Το'): 1, ('Το', 'κοτόπουλο'): 1, ('κοτόπουλο', 'είναι'): 1, ('είναι', 'το'): 1, ('το', 'αγαπημένο'): 1, ('αγαπημένο', 'μου'): 1, ('μου', 'φαγητό'): 1, ('φαγητό', '.'): 1, ('.', 'Μπορώ'): 1, ('Μπορώ', 'να'): 1, ('να', 'έχω'): 1, ('έχω', 'λίγο'): 1, ('λίγο', 'περισσότερο'): 1, ('περισσότερο', 'ψωμί'): 1, ('ψωμί', ','): 1, (',', 'παρακαλώ'): 1, ('παρακαλώ', ';'): 1, (';', 'Αυτή'): 1, ('Αυτή', 'η'): 1, ('η', 'μηλόπιτα'): 1, ('μηλόπιτα', 'είναι'): 1, ('είναι', 'πολύ'): 2, ('πολύ', 'νόστιμη'): 1, ('νόστιμη', '.'): 1, ('.', 'Πού'): 1, ('Πού', 'αγόρασες'): 1, ('αγόρασες', 'αυτά'): 1, ('αυτά', 'τα'): 1, ('τα', 'φρέσκα'): 1, ('φρέσκα', 'φρούτα'): 1, ('φρούτα', ';'): 1, (';', 'Φτιάχνω'): 1, ('Φτιάχνω', 'σαλάτα'): 1, ('ντομάτες', 'και'): 1, ('και', 'αγγούρια'): 1, ('αγγούρια', '.'): 1, ('.', 'Θα'): 1, ('Θα', 'πιείτε'): 1, ('πιείτε', 'γάλα'): 1, ('γάλα', 'ή'): 1, ('ή', 'χυμό'): 1, ('χυμό', ';'): 1, (';', 'Τα'): 1, ('Τα', 'παιδιά'): 1, ('παιδιά', 'δεν'): 1, ('δεν', 'τρώνε'): 1, ('τρώνε', 'πολύ'): 1, ('πολύ', 'ψωμί'): 1, ('ψωμί', '.'): 1, ('.', 'Αυτές'): 1, ('Αυτές', 'οι'): 1, ('οι', 'ντομάτες'): 1, ('ντομάτες', 'είναι'): 1, ('πολύ', 'ώριμες'): 1, ('ώριμες', '.'): 1, ('.', 'Στο'): 1, ('Στο', 'πρωινό'): 1, ('πρωινό', 'μου'): 1, ('μου', 'πάντα'): 1, ('πάντα', 'έχω'): 1, ('έχω', 'ένα'): 1, ('.', 'Τα'): 1, ('Τα', 'φρούτα'): 1, ('φρούτα', 'είναι'): 1, ('είναι', 'καλά'): 1, ('καλά', 'για'): 1, ('για', 'την'): 1, ('την', 'υγεία'): 1, ('υγεία', '.'): 1}\n"
     ]
    }
   ],
   "source": [
    "#counting Bigrams\n",
    "bigram_count = {}\n",
    "for i in range(len(doc) - 1):\n",
    "    bigram = (doc[i].text, doc[i+1].text) \n",
    "    if bigram in bigram_count:\n",
    "        bigram_count[bigram] += 1\n",
    "    else:\n",
    "        bigram_count[bigram] = 1\n",
    "print(bigram_count)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = nlp_grk(\"Τρώω τυρί και ελιές τα σαββατοκύριακα.\")\n",
    "sentence2 = nlp_grk(\"Στην Ελλάδα, οι άνθρωποι απολαμβάνουν μια πλούσια ποικιλία τροφίμων που περιλαμβάνει φρέσκα θαλασσινά, λαχταριστά παραδοσιακά πιάτα όπως μουσακά και σουβλάκι, αρωματικά μπαχαρικά και βότανα, καθώς και μια εκπληκτική ποικιλία τυριών και ελιών, απολαμβάνοντας το φαγητό τους με καλό κρασί ή ούζο.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0752688172043013e-07\n",
      "-23.14879928554484\n"
     ]
    }
   ],
   "source": [
    "#Sentence 1 probability\n",
    "import math\n",
    "\n",
    "s1_probability = 0\n",
    "total_unigrams = len(unigram_count)\n",
    "product_s1_prob = 1\n",
    "\n",
    "for i in range(len(sentence1)):\n",
    "    if i == 0:\n",
    "        word = sentence1[0].text\n",
    "        count_of_word = unigram_count[word] if word in unigram_count else 1\n",
    "        product_s1_prob *= count_of_word/total_unigrams #sum without log\n",
    "        s1_probability += math.log(count_of_word/total_unigrams, 2)\n",
    "    else:\n",
    "        bigram = (sentence1[i-1].text, sentence1[i].text)\n",
    "        count_of_bigram = bigram_count[bigram] if bigram in bigram_count else 1\n",
    "        count_of_prev_unigram = unigram_count[sentence1[0].text] if sentence1[0].text in unigram_count else 1\n",
    "        product_s1_prob *= count_of_bigram/count_of_prev_unigram  #sum without log\n",
    "        s1_probability += math.log(count_of_bigram/count_of_prev_unigram, 2)\n",
    "    \n",
    "print(product_s1_prob)\n",
    "print(s1_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010752688172043012\n",
      "-6.539158811108032\n"
     ]
    }
   ],
   "source": [
    "#Sentence 2 probability\n",
    "import math\n",
    "\n",
    "s2_probability = 0\n",
    "total_unigrams = len(unigram_count)\n",
    "product_s2_prob = 1\n",
    "\n",
    "for i in range(len(sentence2)):\n",
    "    if i == 0:\n",
    "        word = sentence2[0].text\n",
    "        count_of_word = unigram_count[word] if word in unigram_count else 1\n",
    "        product_s2_prob *= count_of_word/total_unigrams #sum without log\n",
    "        s2_probability += math.log(count_of_word/total_unigrams, 2)\n",
    "    else:\n",
    "        bigram = (sentence2[i-1].text, sentence2[i].text)\n",
    "        count_of_bigram = bigram_count[bigram] if bigram in bigram_count else 1\n",
    "        count_of_prev_unigram = unigram_count[sentence2[0].text] if sentence2[0].text in unigram_count else 1\n",
    "        product_s2_prob *= count_of_bigram/count_of_prev_unigram  #sum without log\n",
    "        s2_probability += math.log(count_of_bigram/count_of_prev_unigram, 2)\n",
    "\n",
    "print(product_s2_prob)\n",
    "print(s2_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.89686312787056\n"
     ]
    }
   ],
   "source": [
    "#Perplexity of Sentence 1\n",
    "N = len(sentence1)\n",
    "inverse_N = -1/N\n",
    "s1_perplexity = (product_s1_prob)**(inverse_N)\n",
    "print(s1_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1012416182200493\n"
     ]
    }
   ],
   "source": [
    "#Perplexity of Sentence 2\n",
    "N = len(sentence2)\n",
    "inverse_N = -1/N\n",
    "s2_perplexity = (product_s2_prob)**(inverse_N)\n",
    "print(s2_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
